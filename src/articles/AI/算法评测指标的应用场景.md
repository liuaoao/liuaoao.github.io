# 算法评测指标的应用场景

## precision / recall / f1-score

1. 阈值较高时，Precision比较大，阈值较低时，Recall较大。
2. precision描述的是识别值中的正确率，推荐（信息检索）的话，需要Precision较大，用户希望排名靠前的推荐是自己想要的；
3. 而recall描述的是真值中的正确率，所以刑侦的话希望Recall较大，不错过一个犯人。
4. 而f1-score的话是一个综合指标，如果precision和recall都较大时，f1-score则更大。

## PR / ROC

### PR

所以在类别不平衡的问题下，负样本数量众多时，FP增多，对precision和PR曲线变化较大，此时对于更加关注precision的场景难以接受。

### ROC优点

1. TPR考虑正样本，FPR考虑负样本，所以ROC对正、负样本兼顾。
2. ROC的指标TPR、FPR都是比例，不依赖于样本类别的分布。
3. TPR的分母是正样本数，FPR的分母是负样本数，正样本或者负样本总数发生变化（例如比例相差很大），不会影响到另一部分。而Precision=TP/(TP+FP)的分母来自正、负样本两部分，易受类别分布影响。假设负样本增加10倍，ROC曲线不变，因为FP和N都增加了，但PR曲线会变化较大，因为FP增加，precision变了。这也是ROC的优点，具有鲁棒性，**在类别分布发生明显变化时依然能识别较好的分类器**。同一个模型用在不同的样本集上，能够得到相似的ROC曲线。

### ROC缺点

1. 优点3.提到**ROC不会随类别分布的改变而改变**，既是优点也是缺点。例如负样本N增加10倍，会产生更多的FP，但ROC曲线却没怎么变。信息检索领域特别在乎precision，这就无法接受：同一个模型在两个不同样本集上ROC表现相似，但在负样本远多的那个样本上，precision会小很多。
2. **label不平衡情况下**，负样本数量众多，并不会使FPR明显增大，导致**ROC评估过分乐观**。当负样本数量远超正样本，FP大量增加，大量负样本被预测为positive，却只换来FPR的微小改变，ROC曲线无法体现。

### PR与ROC的比较

1. ROC曲线兼顾正样本与负样本，所以适用于评估分类器的整体性能，相比而言PR曲线完全聚焦于正样本。
2. 类别不平衡问题，常常只关心正样本的预测情况，所以该**一般情况**下PR曲线被认为优于ROC曲线。如果想要评估在**相同**的类别分布下正样本的预测情况，适合选PR曲线。参考[1]的imbalance样本的例子，ROC-AUC为0.8左右，PR-AUC为0.68左右，ROC估计比较乐观，因为precision受到FP的影响，PR-AUC会低一些。
3. 如果有**多份数据**且存在**不同**的类别分布，比如信用卡欺诈问题中每个月正、负样本的比例可能都不相同，这时候如果只想单纯地比较分类器的性能且剔除类别分布改变的影响，则ROC曲线比较适合，因为类别分布改变可能使得PR曲线发生变化时好时坏，难以进行模型比较；反之，如果想测试不同类别分布下对分类器的性能的影响，则PR曲线比较适合。
4. 根据实际情况，选择ROC或者PR来评估分类器，找到曲线上最优的点，选择最合适的threshold
5. （总结）在固定的数据集上，PR曲线更直观的反映其性能。假如数据集不同（如不同的测试集），PR曲线的变化太大，ROC曲线更加稳定。

# SPE使用到的算法指标（模型效果）

1、分类——accuracy：简单，方便快速计算。精度只是简单地计算出比例，但是没有对不同类别进行区分，因而无法得知具体类别下的错误率和精度。

2、目标检测、实例分割——mAP：本质上还是属于【信息检索】的领域，所以用户会更加关注被识别出来的、precision的部分，所以普遍使用了基于PR曲线的mAP的指标。

3、语义分割——mIoU：使用最为广泛，计算方便。它是针对整个数据集而言，因此只有整体的像素分割准确信息，没有具体类别的分割准确信息。

4、OCR——hmean（e2e_f1-score）：同时反应了precision和recall